{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9ec368",
   "metadata": {},
   "source": [
    "# Deepchecks step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f059606",
   "metadata": {},
   "source": [
    "### 1) Prepare repository structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67867d9a",
   "metadata": {},
   "source": [
    "Deepchecks needs a repository structure to operate correctly, so first of all we need to correctly prepare the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb0651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1369d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalation\n",
    "# !python -m pip install \"deepchecks[vision]\" pyyaml pillow --upgrade\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil, yaml\n",
    "from PIL import Image\n",
    "\n",
    "# Routes \n",
    "BASE_TRAIN = Path(\"../data/raw/dataset_train_rgb\")\n",
    "BASE_TEST  = Path(\"../data/raw/dataset_test_rgb\")\n",
    "IMAGES_TRAIN_DIR = BASE_TRAIN / \"rgb\" / \"train\"\n",
    "IMAGES_TEST_DIR  = BASE_TEST  / \"rgb\" / \"test\"\n",
    "TRAIN_YAML = BASE_TRAIN / \"train.yaml\"\n",
    "TEST_YAML  = BASE_TEST /  \"test.yaml\"\n",
    "CLS_ROOT = Path(\"cls_data\")  # output repository\n",
    "\n",
    "# Given that we have several labels for the same color, we will group them\n",
    "SUPERMAP = {\n",
    "    # Green\n",
    "    \"Green\": \"Green\", \"GreenLeft\": \"Green\", \"GreenRight\": \"Green\",\n",
    "    \"GreenStraight\": \"Green\", \"GreenStraightLeft\": \"Green\", \"GreenStraightRight\": \"Green\",\n",
    "    # Red\n",
    "    \"Red\": \"Red\", \"RedLeft\": \"Red\", \"RedRight\": \"Red\",\n",
    "    \"RedStraight\": \"Red\", \"RedStraightLeft\": \"Red\",\n",
    "    # Yellow\n",
    "    \"Yellow\": \"Yellow\",\n",
    "    # Off\n",
    "    \"off\": \"off\",\n",
    "}\n",
    "VALID_CLASSES = {\"Green\",\"Red\",\"Yellow\",\"off\"}\n",
    "\n",
    "def load_yaml_list(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def resolve_img_path(raw_path: str, images_dir: Path, base_dir: Path):\n",
    "    \"\"\"\n",
    "    Given a yaml file, it gets the routes:\n",
    "    * If absolute routes -> use basename in images_dir\n",
    "    * If relative route -> use base_dir/raw_path\n",
    "    \"\"\"\n",
    "    p = Path(raw_path)\n",
    "    if p.is_absolute():\n",
    "        return (images_dir / p.name).resolve()\n",
    "    cand = (base_dir / p).resolve()\n",
    "    return cand if cand.is_file() else (images_dir / p.name).resolve()\n",
    "\n",
    "def sanitize_box(b, W, H):\n",
    "    \"\"\"Normalize and clip a bounding box to image bounds; return (x1,y1,x2,y2) or None if degenerate.\"\"\"\n",
    "    x1, y1 = float(b[\"x_min\"]), float(b[\"y_min\"])\n",
    "    x2, y2 = float(b[\"x_max\"]), float(b[\"y_max\"])\n",
    "    if x2 < x1: x1, x2 = x2, x1\n",
    "    if y2 < y1: y1, y2 = y2, y1\n",
    "    x1 = max(0.0, min(x1, W)); x2 = max(0.0, min(x2, W))\n",
    "    y1 = max(0.0, min(y1, H)); y2 = max(0.0, min(y2, H))\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def ensure_dir(d):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def link_or_copy(src: Path, dst: Path):\n",
    "    \"\"\"Intenta enlace duro; si no, symlink; si no, copia.\"\"\"\n",
    "    if dst.exists():\n",
    "        return\n",
    "    try:\n",
    "        os.link(src, dst)               # hardlink (no duplica bytes)\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.symlink(src, dst)        # symlink\n",
    "        except Exception:\n",
    "            shutil.copy2(src, dst)      # copia\n",
    "\n",
    "def build_classification_split(items, images_dir: Path, base_dir: Path, out_dir: Path, max_per_class=None):\n",
    "    \"\"\"\n",
    "    Create class folders with images that have EXACTLY one valid bounding box,\n",
    "    mapping each label to {Red, Yellow, Green, off}.\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    counts = {c:0 for c in VALID_CLASSES}\n",
    "    kept, skipped = 0, 0\n",
    "\n",
    "    for it in items:\n",
    "        # resolver imagen\n",
    "        img_path = resolve_img_path(it[\"path\"], images_dir, base_dir)\n",
    "        if not img_path.is_file():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # cargar y sanear cajas\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        W, H = img.size\n",
    "\n",
    "        boxes = []\n",
    "        for b in (it.get(\"boxes\") or []):\n",
    "            superlab = SUPERMAP.get(str(b.get(\"label\")))\n",
    "            if superlab not in VALID_CLASSES:\n",
    "                continue\n",
    "            sb = sanitize_box(b, W, H)\n",
    "            if sb is None:\n",
    "                continue\n",
    "            boxes.append(superlab)\n",
    "\n",
    "        # criterio: exactamente 1 caja -> una sola etiqueta para clasificación\n",
    "        if len(boxes) != 1:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        cls = boxes[0]\n",
    "        if max_per_class is not None and counts[cls] >= max_per_class:\n",
    "            continue\n",
    "\n",
    "        cls_dir = out_dir / cls\n",
    "        ensure_dir(cls_dir)\n",
    "        dst = cls_dir / img_path.name\n",
    "        Path(dst).parent.mkdir(parents=True, exist_ok=True)  # create if it doesn't exist\n",
    "        shutil.copy2(img_path, dst)\n",
    "        counts[cls] += 1\n",
    "        kept += 1\n",
    "\n",
    "    return counts, kept, skipped\n",
    "\n",
    "# Execute this for train and test\n",
    "y_train = load_yaml_list(TRAIN_YAML)\n",
    "y_test  = load_yaml_list(TEST_YAML)\n",
    "\n",
    "train_counts, train_kept, train_skipped = build_classification_split(\n",
    "    y_train, IMAGES_TRAIN_DIR, BASE_TRAIN, CLS_ROOT / \"train\", max_per_class=None\n",
    ")\n",
    "test_counts, test_kept, test_skipped = build_classification_split(\n",
    "    y_test, IMAGES_TEST_DIR, BASE_TEST, CLS_ROOT / \"test\", max_per_class=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76b387",
   "metadata": {},
   "source": [
    "### 2) Explore file structure output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb38d1",
   "metadata": {},
   "source": [
    "Since we’ve removed all images with multiple or zero bounding boxes, this step just helps us see how many valid single-box images remain in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "807c0c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN stats: Counter({'multi_boxes': 2789, 'zero_boxes': 1940, 'one_box': 364})\n",
      "TEST stats: Counter({'multi_boxes': 5253, 'one_box': 1894, 'zero_boxes': 1187})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "stats = Counter()\n",
    "for it in y_train:\n",
    "    boxes = it.get(\"boxes\") or []\n",
    "    if len(boxes) == 0: stats['zero_boxes'] += 1\n",
    "    elif len(boxes) == 1: stats['one_box'] += 1\n",
    "    else: stats['multi_boxes'] += 1\n",
    "print(\"TRAIN stats:\", stats)\n",
    "\n",
    "stats = Counter()\n",
    "for it in y_test:\n",
    "    boxes = it.get(\"boxes\") or []\n",
    "    if len(boxes) == 0: stats['zero_boxes'] += 1\n",
    "    elif len(boxes) == 1: stats['one_box'] += 1\n",
    "    else: stats['multi_boxes'] += 1\n",
    "print(\"TEST stats:\", stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d5f05",
   "metadata": {},
   "source": [
    "### 3) Deepchecks validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c8f5171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/opt/anaconda3/envs/mlopsenv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> output_deepchecks_cls.html\n"
     ]
    }
   ],
   "source": [
    "# Instalation\n",
    "#!python -m pip uninstall -y torchvision torch\n",
    "#!python -m pip cache purge\n",
    "#!python -m pip install --no-cache-dir torch==2.4.1 torchvision==0.19.1\n",
    "\n",
    "from deepchecks.vision import classification_dataset_from_directory\n",
    "from deepchecks.vision.suites import train_test_validation\n",
    "\n",
    "ROOT = \"cls_data\"\n",
    "\n",
    "train_ds, test_ds = classification_dataset_from_directory(\n",
    "    root=ROOT, object_type='VisionData', image_extension='png'\n",
    ")\n",
    "\n",
    "suite = train_test_validation()\n",
    "result = suite.run(train_ds, test_ds)\n",
    "result.save_as_html('output_deepchecks_cls.html', as_widget=False, requirejs=False)\n",
    "print(\"OK -> output_deepchecks_cls.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd53dc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "import webbrowser, os\n",
    "webbrowser.open(\"file://\" + os.path.abspath(\"output_deepchecks_cls.html\",))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
