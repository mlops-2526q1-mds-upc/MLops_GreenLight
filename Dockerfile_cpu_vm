# Base image with Ubuntu + Python 3.10 (no CUDA)
FROM python:3.9-slim-bullseye


# Working directory inside the container
WORKDIR /workspace
COPY . .

# Prevent Python from buffering stdout and stderr
ENV PYTHONUNBUFFERED=1

# ------------------------------
# Install system dependencies
# ------------------------------
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    wget \
    curl \
    cmake \
    g++ \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgl1 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# ------------------------------
# Upgrade pip
# ------------------------------
RUN python3 -m pip install --upgrade pip

# ------------------------------
# Install PyTorch (CPU only, no CUDA)
# ------------------------------
# 2) Install CPU PyTorch that Detectron2 has wheels for (torch 1.13.1)
RUN python -m pip install --upgrade pip && \
    python -m pip install --no-cache-dir \
        torch==1.10.0+cpu \
        torchvision==0.11.1+cpu \
        -f https://download.pytorch.org/whl/cpu/torch_stable.html




# 3) Install Detectron2 from prebuilt CPU wheels for torch1.13
RUN python -m pip install --no-cache-dir \
    detectron2 \
    -f https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.10/index.html

# ------------------------------
# Install additional ML libraries
# ------------------------------
RUN pip install --no-cache-dir \
    opencv-python \
    matplotlib \
    tqdm \
    jupyter \
    notebook \
    pyyaml \
    omegaconf \
    hydra-core \
    codecarbon \
    mlflow \
    uvc \
    dagshub \
    dvc \
    fastapi \
    "uvicorn[standard]" \
    "pillow<10" \
    python-multipart \
    "numpy<2.0"

RUN pip install --no-cache-dir --force-reinstall \
    "numpy==1.24.4" \
    "pillow==9.5.0"


# -- optional --    
RUN python - <<'PY'
import PIL, numpy, torch, PIL.Image as I
print("Pillow", PIL.__version__)
print("NumPy", numpy.__version__)
print("Torch", torch.__version__)
print("Has Image.LINEAR?", hasattr(I,"LINEAR"))
PY



# ------------------------------
# Expose ports
# - 8888: Jupyter (if you still use it)
# - 8000: FastAPI inference API
# ------------------------------
EXPOSE 8888
EXPOSE 8000

# ------------------------------
# Default command when container starts
# ------------------------------
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]



